// filename: test/scala/IssueToAluAndLsuSpec.scala
// testOnly test.scala.IssueToAluAndLsuSpec
package test.scala

import org.scalatest.funsuite.AnyFunSuite
import parallax.common._
import parallax.components.rename._
import parallax.components.rob._
import parallax.execute.{AluIntEuPlugin, LsuEuPlugin, WakeupPlugin, BypassPlugin}
import parallax.fetch._
import parallax.issue._
import parallax.components.bpu.BpuPipelinePlugin
import parallax.components.lsu._
import parallax.components.dcache2._
import parallax.components.memory._
import parallax.bus._
import spinal.core._
import spinal.core.sim._
import spinal.lib._
import parallax.utilities._
import spinal.lib.bus.amba4.axi.{Axi4Config, Axi4}

import scala.collection.mutable
import scala.util.Random
import spinal.lib.bus.amba4.axi.Axi4CrossbarFactory
import spinal.lib.bus.misc.SizeMapping

// =========================================================================
//  Test Helper Classes
// =========================================================================

/** This plugin provides a concrete memory system implementation (a simulated SRAM)
  * for the DataCache to connect to via the DBusService.
  */
/** This plugin provides a concrete memory system implementation (a simulated SRAM)
  * for the DataCache to connect to via the DBusService, and also provides SGMB
  * interfaces for MMIO operations.
  */
class TestOnlyMemSystemPlugin(axiConfig: Axi4Config, sgmbConfig: Option[GenericMemoryBusConfig] = None)
    extends Plugin
    with DBusService
    with SgmbService {
  import scala.collection.mutable.ArrayBuffer

  // SGMB éƒ¨åˆ†ä¿æŒä¸å˜
  private val readPorts = ArrayBuffer[SplitGmbReadChannel]()
  private val writePorts = ArrayBuffer[SplitGmbWriteChannel]()

  val _sgmbConfig = sgmbConfig.getOrElse(
    GenericMemoryBusConfig(
      addressWidth = 32 bits,
      dataWidth = 32 bits,
      useId = false,
      idWidth = axiConfig.idWidth bits
    )
  )

  override def newReadPort(): SplitGmbReadChannel = {
    ParallaxLogger.debug("CALL newReadPort.")
    this.framework.requireEarly()
    val port = SplitGmbReadChannel(_sgmbConfig)
    readPorts += port
    port
  }

  override def newWritePort(): SplitGmbWriteChannel = {
    ParallaxLogger.debug("CALL newWritePort.")
    this.framework.requireEarly()
    val port = SplitGmbWriteChannel(_sgmbConfig)
    writePorts += port
    port
  }

  override def getBus(): Axi4 = {
    println("CALL getBus.")
    null
  }

  val hw = create early new Area {
    // SRAM å’Œæ§åˆ¶å™¨å®šä¹‰
    private val sramSize = BigInt("4000", 16)
    private val extSramCfg = SRAMConfig(
      addressWidth = 16,
      dataWidth = 32,
      virtualBaseAddress = BigInt("00000000", 16),
      sizeBytes = sramSize,
      readWaitCycles = 0,
      enableLog = true
    )
    val sram = new SimulatedSRAM(extSramCfg)
    val numMasters = 1 /*cache*/ + 5 /*å…ˆè¿™æ ·å§*/;
    val ctrl =
      new SRAMController(
        axiConfig.copy(idWidth = axiConfig.idWidth + log2Up(numMasters)),
        extSramCfg
      ) // è¿™ç©æ„å„¿æ˜¯slaveï¼Œå¿…é¡»ç•™ä¸€äº›é«˜ä½ç”¨æ¥åŒºåˆ†master
    ctrl.io.ram <> sram.io.ram
    ctrl.io.simPublic()
    sram.io.simPublic()
  }

  val logic = create late new Area {
    lock.await()
    val dcacheMaster = getService[DataCachePlugin].getDCacheMaster
    val readBridges = readPorts.map(_ => new SplitGmbToAxi4Bridge(_sgmbConfig, axiConfig))
    val writeBridges = writePorts.map(_ => new SplitGmbToAxi4Bridge(_sgmbConfig, axiConfig))
    ParallaxLogger.debug(s"readBridges.size = ${readBridges.size}, writeBridges.size = ${writeBridges.size}")
    for ((port, bridge) <- readPorts.zip(readBridges)) {
      bridge.io.gmbIn.read.cmd <> port.cmd
      bridge.io.gmbIn.read.rsp <> port.rsp
      bridge.io.gmbIn.write.cmd.setIdle()
      bridge.io.gmbIn.write.rsp.ready := True
    }
    for ((port, bridge) <- writePorts.zip(writeBridges)) {
      bridge.io.gmbIn.write.cmd <> port.cmd
      bridge.io.gmbIn.write.rsp <> port.rsp
      bridge.io.gmbIn.read.cmd.setIdle()
      bridge.io.gmbIn.read.rsp.ready := True
    }
    val sramMasters = writeBridges.map(_.io.axiOut) ++ readBridges.map(_.io.axiOut) ++ Seq(dcacheMaster)
    sramMasters.zipWithIndex.foreach { case (master, index) =>
      ParallaxLogger.info(s"  Master $index: idWidth = ${master.config.idWidth}")
    }
    require(sramMasters.size <= hw.numMasters, "Too many masters for SRAM controller")
    val crossbar = Axi4CrossbarFactory()
    val sramSize = BigInt("4000", 16)
    crossbar.addSlave(hw.ctrl.io.axi, SizeMapping(0x0000L, sramSize))
    for (master <- sramMasters) {
      crossbar.addConnection(master, Seq(hw.ctrl.io.axi))
    }
    crossbar.build()

  }

  def getSram(): SimulatedSRAM = hw.sram
}

// =========================================================================
//  Mock Services & Test Bench Helpers
// =========================================================================

class MockFetchServiceForLsu(pCfg: PipelineConfig) extends Plugin with SimpleFetchPipelineService {
  val fetchStreamIn = Stream(FetchedInstr(pCfg))
  override def fetchOutput(): Stream[FetchedInstr] = fetchStreamIn
  override def newHardRedirectPort(priority: Int): Flow[UInt] = Flow(UInt(pCfg.pcWidth))
  override def newFetchDisablePort(): Bool = Bool()
}

// Mock flush source to provide default values for ROB flush signals
class MockFlushService(pCfg: PipelineConfig) extends Plugin {
  val logic = create late new Area {
    val robService = getService[ROBService[RenamedUop]]
    val robFlushPort = robService.newRobFlushPort()

    // Create a register to drive targetRobPtr to avoid constant optimization issues
    val flushTargetReg = Reg(UInt(pCfg.robPtrWidth)) init (0)

    // Provide default inactive values
    robFlushPort.valid := False
    robFlushPort.payload.reason := FlushReason.NONE
    robFlushPort.payload.targetRobPtr := flushTargetReg // Use register instead of constant
  }
}

// =========================================================================
//  The Test Bench (original LSU-only)
// =========================================================================

class IssueToAluAndLsuTestBench(val pCfg: PipelineConfig, val isIO: Boolean = false) extends Component {
  ParallaxLogger.warning(s"pCfg.totalEuCount = ${pCfg.totalEuCount}");

  val UOP_HT = HardType(RenamedUop(pCfg))

  val io = new Bundle {
    val fetchStreamIn = slave(Stream(FetchedInstr(pCfg)))
    val enableCommit = in Bool ()
    // Expose commit port for monitoring
    val commitValid = out Bool ()
    val commitEntry = out(
      ROBFullEntry(
        ROBConfig(
          robDepth = pCfg.robDepth,
          pcWidth = pCfg.pcWidth,
          commitWidth = pCfg.commitWidth,
          allocateWidth = pCfg.renameWidth,
          numWritebackPorts = pCfg.totalEuCount,
          uopType = UOP_HT,
          defaultUop = () => RenamedUop(pCfg).setDefault(),
          exceptionCodeWidth = pCfg.exceptionCodeWidth
        )
      )
    )
  }

  // åœ¨Frameworkåˆ›å»ºå‰ç»Ÿä¸€åˆ›å»ºæ‰€æœ‰é…ç½®
  val lsuConfig = LsuConfig(
    lqDepth = 16,
    sqDepth = 16,
    robPtrWidth = pCfg.robPtrWidth,
    pcWidth = pCfg.pcWidth,
    dataWidth = pCfg.dataWidth,
    physGprIdxWidth = pCfg.physGprIdxWidth,
    exceptionCodeWidth = pCfg.exceptionCodeWidth,
    commitWidth = pCfg.commitWidth,
    dcacheRefillCount = 2
  )

  val dCacheConfig = DataCachePluginConfig(
    pipelineConfig = pCfg,
    memDataWidth = pCfg.dataWidth.value,
    cacheSize = 1024,
    wayCount = 2,
    refillCount = 2,
    writebackCount = 2,
    lineSize = 64,
    transactionIdWidth = pCfg.transactionIdWidth
  )

  val dCacheParams = DataCachePluginConfig.toDataCacheParameters(dCacheConfig)
  val axiConfig = Axi4Config(
    addressWidth = pCfg.xlen,
    dataWidth = pCfg.xlen,
    idWidth = lsuConfig.robPtrWidth.value,
    useLock = false,
    useCache = false,
    useProt = true,
    useQos = false,
    useRegion = false,
    useResp = true,
    useStrb = true,
    useBurst = true,
    useLen = true,
    useSize = true
  )

  val sgmbConfig = GenericMemoryBusConfig(
    addressWidth = pCfg.xlen bits,
    dataWidth = pCfg.xlen bits,
    useId = true,
    idWidth = axiConfig.idWidth bits
  )

  val mmioConfig = if (isIO) {
    Option(sgmbConfig)
  } else {
    None
  }

  println("mmioConfig = ", mmioConfig)

  val renameMapConfig = RenameMapTableConfig(
    archRegCount = pCfg.archGprCount,
    physRegCount = pCfg.physGprCount,
    numReadPorts = pCfg.renameWidth * 3,
    numWritePorts = pCfg.renameWidth
  )

  val flConfig = SimpleFreeListConfig(
    numPhysRegs = pCfg.physGprCount,
    
    numInitialArchMappings = pCfg.archGprCount,
    numAllocatePorts = pCfg.renameWidth,
    numFreePorts = pCfg.commitWidth
  )

  val framework = new Framework(
    Seq(
      new MockFetchServiceForLsu(pCfg),
      // new MockFlushService(pCfg),  // Add mock flush service
      new PhysicalRegFilePlugin(pCfg.physGprCount, pCfg.dataWidth),
      new BusyTablePlugin(pCfg),
      new ROBPlugin[RenamedUop](pCfg, HardType(RenamedUop(pCfg)), () => RenamedUop(pCfg).setDefault()),
      new WakeupPlugin(pCfg),
      new BypassPlugin[BypassMessage](payloadType = HardType(BypassMessage(pCfg))),
      new CommitPlugin(pCfg),
      new BpuPipelinePlugin(pCfg),
      new LoadQueuePlugin(pCfg, lsuConfig, dCacheParams, lsuConfig.lqDepth, mmioConfig),
      new StoreBufferPlugin(pCfg, lsuConfig, dCacheParams, lsuConfig.sqDepth, mmioConfig),
      new AguPlugin(lsuConfig, supportPcRel = true),
      new DataCachePlugin(dCacheConfig),
      new TestOnlyMemSystemPlugin(axiConfig, Some(sgmbConfig)),
      new IssuePipeline(pCfg),
      new DecodePlugin(pCfg),
      new CheckpointManagerPlugin(pCfg, renameMapConfig, flConfig),
      new RenameMapTablePlugin(ratConfig = renameMapConfig),
      new SuperScalarFreeListPlugin(flConfig),
      new RenamePlugin(pCfg, renameMapConfig, flConfig),
      new RobAllocPlugin(pCfg),
      new IssueQueuePlugin(pCfg),
      // Add ALU EU for ADDI support and LSU EU for store/load
      new AluIntEuPlugin("AluEU", pCfg),
      new LsuEuPlugin("LsuEU", pCfg, lsuConfig, dCacheParams, isIO),
      new LinkerPlugin(pCfg),
      new DispatchPlugin(pCfg)
    )
  )

  val fetchService = framework.getService[MockFetchServiceForLsu]
  fetchService.fetchStreamIn << io.fetchStreamIn

  val commitController = framework.getService[CommitPlugin]
  commitController.setCommitEnable(io.enableCommit)

  val robService = framework.getService[ROBService[RenamedUop]]
  val commitSlot = robService.getCommitSlots(pCfg.commitWidth).head
  io.commitValid := commitSlot.canCommit
  io.commitEntry := commitSlot.entry

  // Expose memory system for verification
  val memSystem = framework.getService[TestOnlyMemSystemPlugin]

  // Connect fetch service to issue pipeline
  val issuePipeline = framework.getService[IssuePipeline]
  val fetchOutStream = fetchService.fetchOutput()
  val issueEntryStage = issuePipeline.entryStage
  val issueSignals = issuePipeline.signals

  issueEntryStage.valid := fetchOutStream.valid
  fetchOutStream.ready := issueEntryStage.isReady

  val fetched = fetchOutStream.payload
  val instructionVec = Vec(Bits(pCfg.dataWidth), pCfg.fetchWidth)
  instructionVec(0) := fetched.instruction
  for (i <- 1 until pCfg.fetchWidth) {
    instructionVec(i) := 0
  }

  issueEntryStage(issueSignals.GROUP_PC_IN) := fetched.pc
  issueEntryStage(issueSignals.RAW_INSTRUCTIONS_IN) := instructionVec
  issueEntryStage(issueSignals.VALID_MASK) := B"1"
  issueEntryStage(issueSignals.IS_FAULT_IN) := False

  // === PRF Access for Architectural Register Verification ===
  val prfService = framework.getService[PhysicalRegFileService]
  val prfReadPort = prfService.newPrfReadPort()
  prfReadPort.simPublic()
  prfReadPort.valid := False
  prfReadPort.address := 0
  // === RAT Query Interface for Testing ===
  val ratService = framework.getService[RatControlService]
  val ratMapping = ratService.getCurrentState().mapping
  ratMapping.simPublic()

  // === Memory System for Direct Access ===
  val memSystemPlugin = framework.getService[TestOnlyMemSystemPlugin]
  val sram = memSystemPlugin.getSram()
  sram.io.simPublic()
}

// =========================================================================
//  Helper Functions for Architectural Register Verification
// =========================================================================

object IssueToAluAndLsuSpecHelper {
  def readArchReg(dut: IssueToAluAndLsuTestBench, archRegIdx: Int): BigInt = {
    val cd = dut.clockDomain
    val physRegIdx = dut.ratMapping(archRegIdx).toBigInt
    dut.prfReadPort.valid #= true
    dut.prfReadPort.address #= physRegIdx
    dut.clockDomain.waitSampling(1)
    val rsp = dut.prfReadPort.rsp.toBigInt
    dut.prfReadPort.valid #= false
    return rsp
  }

  def readMemoryWord(dut: IssueToAluAndLsuTestBench, address: BigInt): BigInt = {
    val cd = dut.clockDomain

    // Use SRAM testbench interface for direct memory access
    dut.sram.io.tb_readEnable #= true
    dut.sram.io.tb_readAddress #= address // ç›´æ¥ä½¿ç”¨å­—èŠ‚åœ°å€ï¼Œä¸DCacheä¸€è‡´
    dut.sram.io.tb_writeEnable #= false

    // Wait a few cycles for SRAM read
    cd.waitSampling(3)

    val data = dut.sram.io.tb_readData.toBigInt

    // Clean up
    dut.sram.io.tb_readEnable #= false

    return data
  }
}

// =========================================================================
//  The Test Suite
// =========================================================================

class IssueToAluAndLsuSpec extends CustomSpinalSimFunSuite {

  // åˆ›å»ºæ”¯æŒALUå’ŒLSUçš„é…ç½®ç±»
  class AluAndLsuPipelineConfig
      extends PipelineConfig(
        aluEuCount = 1, // éœ€è¦ALUæ¥æ‰§è¡ŒADDIæŒ‡ä»¤
        lsuEuCount = 1,
        dispatchWidth = 1,
        renameWidth = 1,
        fetchWidth = 1,
        xlen = 32,
        physGprCount = 64,
        archGprCount = 32,
        robDepth = 16,
        commitWidth = 1,
        transactionIdWidth = 8
      ) {}

  val pCfg_complex = new AluAndLsuPipelineConfig() // å¤æ‚æµ‹è¯•ä½¿ç”¨ALU+LSUé…ç½®

  test("StoreAndLoad_Test") {
    // ä½¿ç”¨ALU+LSUé…ç½®æ¥æ”¯æŒADDIæŒ‡ä»¤
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .allOptimisation
      .workspacePath("simWorkspace/scala_sim")
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex))

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(30000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(s"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      // Simple commit monitoring with detailed logging
      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")

            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹Storeå’ŒLoadæµ‹è¯• ===")
      dut.io.enableCommit #= false
      cd.waitSampling(5)

      // çœŸæ­£æœ‰è¯´æœåŠ›çš„æµ‹è¯•åºåˆ—ï¼š
      // 1. ADDI r3, r0, 0x123  (r3 = 0 + 0x123 = 0x123, ç»™r3è®¾ç½®ä¸€ä¸ªéé›¶å€¼)
      // 2. ST.W r3, r0, 0x200  (å­˜å‚¨r3çš„å€¼0x123åˆ°åœ°å€0x200)
      // 3. LD.W r1, r0, 0x200  (ä»åœ°å€0x200åŠ è½½ï¼Œåº”è¯¥å¾—åˆ°0x123)
      // 4. ST.W r0, r0, 0x204  (å­˜å‚¨r0çš„å€¼0åˆ°åœ°å€0x204)
      // 5. LD.W r2, r0, 0x204  (ä»åœ°å€0x204åŠ è½½ï¼Œåº”è¯¥å¾—åˆ°0)

      val store_addr = 0x200
      val test_value = 0x123

      val instr_addi = LA32RInstrBuilder.addi_w(rd = 3, rj = 0, imm = test_value) // r3 = r0 + 0x123
      val instr_store1 = LA32RInstrBuilder.st_w(rd = 3, rj = 0, offset = store_addr) // MEM[0x200] = r3 (=0x123)
      val instr_load1 = LA32RInstrBuilder.ld_w(rd = 1, rj = 0, offset = store_addr) // r1 = MEM[0x200]
      val instr_store2 = LA32RInstrBuilder.st_w(rd = 0, rj = 0, offset = store_addr + 4) // MEM[0x204] = r0 (=0)
      val instr_load2 = LA32RInstrBuilder.ld_w(rd = 2, rj = 0, offset = store_addr + 4) // r2 = MEM[0x204]

      println(s"[TEST] å¤šæ•°æ®æ¨¡å¼Storeå’ŒLoadæµ‹è¯•åºåˆ—:")
      println(f"  1. ADDI r3, r0, 0x${test_value}%x (insn=0x${instr_addi}%x) - è®¾ç½®r3=0x${test_value}%x")
      println(f"  2. ST.W r3, r0, 0x${store_addr}%x (insn=0x${instr_store1}%x) - å­˜å‚¨éé›¶å€¼0x${test_value}%x")
      println(f"  3. LD.W r1, r0, 0x${store_addr}%x (insn=0x${instr_load1}%x) - éªŒè¯éé›¶å€¼è¯»å–")
      println(f"  4. ST.W r0, r0, 0x${store_addr + 4}%x (insn=0x${instr_store2}%x) - å­˜å‚¨é›¶å€¼0")
      println(f"  5. LD.W r2, r0, 0x${store_addr + 4}%x (insn=0x${instr_load2}%x) - éªŒè¯é›¶å€¼è¯»å–")

      // å‡†å¤‡æœŸæœ›çš„æäº¤é¡ºåº
      expectedCommits += pc_start // ADDI r3, r0, 0x123
      expectedCommits += (pc_start + 4) // Store 1 (éé›¶å€¼)
      expectedCommits += (pc_start + 8) // Load 1
      expectedCommits += (pc_start + 12) // Store 2 (é›¶å€¼)
      expectedCommits += (pc_start + 16) // Load 2

      println("=== ğŸ“¤ å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start, instr_addi) // PC: 0x00000000
      issueInstr(pc_start + 4, instr_store1) // PC: 0x00000004
      issueInstr(pc_start + 8, instr_load1) // PC: 0x00000008
      issueInstr(pc_start + 12, instr_store2) // PC: 0x0000000C
      issueInstr(pc_start + 16, instr_load2) // PC: 0x00000010

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆ ===")
      cd.waitSampling(30) // ç»™Storeå’ŒLoadåºåˆ—è¶³å¤Ÿçš„å¤„ç†æ—¶é—´

      println("=== âœ… å¯ç”¨æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 600 // å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºæœ‰5æ¡æŒ‡ä»¤
      while (commitCount < 5 && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[WAIT] commitCount=$commitCount/5, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: å¤šæ•°æ®æ¨¡å¼æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº†${commitCount}æ¡æŒ‡ä»¤!")
        assert(commitCount == 5, s"Expected 5 commits, got $commitCount")
        assert(expectedCommits.isEmpty, "Not all expected commits were processed")

        // === éªŒè¯Store/LoadæŒ‡ä»¤åºåˆ—çš„è¯­ä¹‰æ­£ç¡®æ€§ ===
        println("=== ğŸ” éªŒè¯ Store æŒ‡ä»¤é€šè¿‡ Load æŒ‡ä»¤ ===")
        cd.waitSampling(50) // ç­‰å¾…æ›´é•¿æ—¶é—´ç¡®ä¿æ•°æ®ç¨³å®š

        // éªŒè¯ ADDI æŒ‡ä»¤æ˜¯å¦æ­£ç¡®è®¾ç½®äº† r3 = 0x123
        println("éªŒè¯ ADDI æŒ‡ä»¤æ˜¯å¦æ­£ç¡®è®¾ç½®äº† r3 = 0x123")
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)
        assert(r3_value == test_value, s"r3 final value check failed: Result was ${r3_value}, expected ${test_value}")
        println(f"âœ… ADDI æŒ‡ä»¤éªŒè¯é€šè¿‡: r3 = 0x${r3_value}%x")

        // éªŒè¯ Load1 æŒ‡ä»¤ä» Store1 åœ°å€è¯»å–çš„æ•°æ®
        println("éªŒè¯ Load1 æŒ‡ä»¤ä» Store1 åœ°å€è¯»å–çš„æ•°æ®")
        val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
        assert(r1_value == test_value, s"r1 final value check failed: Result was ${r1_value}, expected ${test_value}")
        println(f"âœ… Load1 æŒ‡ä»¤éªŒè¯é€šè¿‡: r1 = 0x${r1_value}%x")

        // éªŒè¯ Load2 æŒ‡ä»¤ä» Store2 åœ°å€è¯»å–çš„æ•°æ®
        println("éªŒè¯ Load2 æŒ‡ä»¤ä» Store2 åœ°å€è¯»å–çš„æ•°æ®")
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        assert(r2_value == 0, s"r2 final value check failed: Result was ${r2_value}, expected 0")
        println(f"âœ… Load2 æŒ‡ä»¤éªŒè¯é€šè¿‡: r2 = 0x${r2_value}%x")

        println("âœ… Store/LoadæŒ‡ä»¤åºåˆ—éªŒè¯å®Œæˆ: Load æŒ‡ä»¤æˆåŠŸè¯»å–åˆ° Store çš„æ•°æ®!")
      } else {
        println("âš ï¸ TIMEOUT: æŒ‡ä»¤æœªèƒ½åœ¨é¢„æœŸæ—¶é—´å†…æäº¤")
        println("è¿™å¯èƒ½è¡¨æ˜LSU EUçš„Store/Loadåºåˆ—å¤„ç†å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦åˆ†ææ—¥å¿—")
        fail("Timeout waiting for commits - Store/Load test failed")
      }

      cd.waitSampling(10)
    }
  }

  test("ComplexLoadStore_Test") {
    // ä½¿ç”¨LSU-only testbenchä½†æ‰§è¡Œæ›´å¤æ‚çš„Store/Loadåºåˆ—
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex))

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(30000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(s"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      // Simple commit monitoring with detailed logging
      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")

            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹å¤æ‚LSUåºåˆ—æµ‹è¯• ===")
      dut.io.enableCommit #= false
      cd.waitSampling(5)

      // å¤æ‚LSUæµ‹è¯•åºåˆ—ï¼ˆé¿å…ä½¿ç”¨ALUï¼Œä¸“æ³¨äºLSUçš„å¤šç§æ“ä½œæ¨¡å¼ï¼‰ï¼š
      // 1. ST.W r0, r0, 0x200  (å­˜å‚¨ï¼šMEM[0x200] = r0 = 0)
      // 2. ST.W r0, r0, 0x204  (å­˜å‚¨ï¼šMEM[0x204] = r0 = 0)
      // 3. LD.W r1, r0, 0x200  (åŠ è½½ï¼šr1 = MEM[0x200] = 0)
      // 4. LD.W r2, r0, 0x204  (åŠ è½½ï¼šr2 = MEM[0x204] = 0)
      // 5. LD.W r3, r0, 0x208  (åŠ è½½ï¼šr3 = MEM[0x208] = æœªåˆå§‹åŒ–)
      // è¿™æµ‹è¯•äº†å¤šä¸ªè¿ç»­çš„Storeå’ŒLoadæ“ä½œï¼Œä»¥åŠStore-to-Load forwarding

      val instr_addi1 = LA32RInstrBuilder.addi_w(rd = 10, rj = 0, imm = 0x123)
      val instr_addi2 = LA32RInstrBuilder.addi_w(rd = 11, rj = 0, imm = 0x456)

      // ä¿®æ”¹æŒ‡ä»¤åºåˆ—
      // 1. ST.W r10, r0, 0x200  (å­˜å‚¨ï¼šMEM[0x200] = 0x123)
      val instr_store1 = LA32RInstrBuilder.st_w(rd = 10, rj = 0, offset = 0x200)
      // 2. ST.W r11, r0, 0x204  (å­˜å‚¨ï¼šMEM[0x204] = 0x456)
      val instr_store2 = LA32RInstrBuilder.st_w(rd = 11, rj = 0, offset = 0x204)
      // 3. LD.W r3, r0, 0x200  (åŠ è½½ï¼šr3 = MEM[0x200] = 0x123)
      val instr_load1 = LA32RInstrBuilder.ld_w(rd = 3, rj = 0, offset = 0x200)
      // 4. LD.W r4, r0, 0x204  (åŠ è½½ï¼šr4 = MEM[0x204] = 0x456)
      val instr_load2 = LA32RInstrBuilder.ld_w(rd = 4, rj = 0, offset = 0x204)
      // 5. LD.W r5, r0, 0x200  (åŠ è½½ï¼šr5 = MEM[0x200] = 0x123, å†æ¬¡åŠ è½½éªŒè¯)
      val instr_load3 = LA32RInstrBuilder.ld_w(rd = 5, rj = 0, offset = 0x200)

      // å‡†å¤‡æœŸæœ›çš„æäº¤é¡ºåº
      expectedCommits += pc_start // Store 1
      expectedCommits += (pc_start + 4) // Store 2
      expectedCommits += (pc_start + 8) // Load 1
      expectedCommits += (pc_start + 12) // Load 2
      expectedCommits += (pc_start + 16) // Load 3

      println("=== ğŸ“¤ å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start, instr_addi1)
      issueInstr(pc_start + 4, instr_addi2)
      issueInstr(pc_start + 8, instr_store1)
      issueInstr(pc_start + 12, instr_store2)
      issueInstr(pc_start + 16, instr_load1)
      issueInstr(pc_start + 20, instr_load2)
      issueInstr(pc_start + 24, instr_load3)

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆ ===")
      cd.waitSampling(50) // ç»™å¤æ‚LSUåºåˆ—æ›´å¤šå¤„ç†æ—¶é—´

      println("=== âœ… å¯ç”¨æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 500 // å¢åŠ è¶…æ—¶æ—¶é—´ç”¨äºå¤æ‚LSUåºåˆ—
      while (commitCount < 5 && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[WAIT] commitCount=$commitCount/5, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: å¤æ‚LSUåºåˆ—æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº†${commitCount}æ¡æŒ‡ä»¤!")
        println("âœ… æµ‹è¯•è¦†ç›–: Store-to-Load forwarding, å¤šé‡Store, å¤šé‡Load, Cache misså¤„ç†")
        assert(commitCount == 5, s"Expected 5 commits, got $commitCount")
        assert(expectedCommits.isEmpty, "Not all expected commits were processed")

        // === éªŒè¯å¤æ‚Store/Loadåºåˆ—çš„è¯­ä¹‰æ­£ç¡®æ€§ ===
        println("ğŸ” å¼€å§‹éªŒè¯å¤æ‚Store/Loadåºåˆ—...")
        cd.waitSampling(50) // ç­‰å¾…æ›´é•¿æ—¶é—´ç¡®ä¿æ•°æ®ç¨³å®š

        // éªŒè¯ç¬¬ä¸‰æ¡æŒ‡ä»¤ lw x3, 0x200 çš„ç»“æœ (åº”è¯¥å¾—åˆ°ç¬¬ä¸€æ¡storeæŒ‡ä»¤çš„å€¼0x123)
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)
        println(s"ğŸ“ å¯„å­˜å™¨ r3 = 0x${r3_value.toString(16)} (æœŸæœ›æ¥è‡ªstore/loadåºåˆ—çš„0x123)")

        // éªŒè¯ç¬¬å››æ¡æŒ‡ä»¤ lw x4, 0x204 çš„ç»“æœ (åº”è¯¥å¾—åˆ°ç¬¬äºŒæ¡storeæŒ‡ä»¤çš„å€¼0x456)
        val r4_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 4)
        println(s"ğŸ“ å¯„å­˜å™¨ r4 = 0x${r4_value.toString(16)} (æœŸæœ›æ¥è‡ªstore/loadåºåˆ—çš„0x456)")

        // éªŒè¯ç¬¬äº”æ¡æŒ‡ä»¤ lw x5, 0x200 çš„ç»“æœ (åº”è¯¥å¾—åˆ°ç¬¬ä¸€æ¡storeæŒ‡ä»¤çš„å€¼0x123)
        val r5_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 5)
        println(s"ğŸ“ å¯„å­˜å™¨ r5 = 0x${r5_value.toString(16)} (æœŸæœ›æ¥è‡ªstore/loadåºåˆ—çš„0x123)")

        // éªŒè¯store/loadåºåˆ—çš„è¯­ä¹‰æ­£ç¡®æ€§
        assert(
          r3_value == BigInt("123", 16),
          s"Store/Load sequence failed for 0x200: r3=0x${r3_value.toString(16)}, expected 0x123"
        )

        assert(
          r4_value == BigInt("456", 16),
          s"Store/Load sequence failed for 0x204: r4=0x${r4_value.toString(16)}, expected 0x456"
        )

        assert(
          r5_value == BigInt("123", 16),
          s"Store/Load sequence failed for 0x200 (second load): r5=0x${r5_value.toString(16)}, expected 0x123"
        )

        println("âœ… å¤æ‚Store/Loadåºåˆ—çš„è¯­ä¹‰éªŒè¯é€šè¿‡!")
        println("   è¿™éªŒè¯äº†StoreæŒ‡ä»¤ã€LoadæŒ‡ä»¤ã€Store-to-Load forwardingå’ŒCacheæ“ä½œçš„æ­£ç¡®æ€§")
        cd.waitSampling(50) // å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œè®©æ•°æ®æœ‰æœºä¼šå†™å›å†…å­˜
      } else {
        println("âš ï¸ TIMEOUT: æŒ‡ä»¤æœªèƒ½åœ¨é¢„æœŸæ—¶é—´å†…æäº¤")
        println("è¿™å¯èƒ½è¡¨æ˜å¤æ‚LSUåºåˆ—å¤„ç†å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦åˆ†æStore/Loadä¾èµ–å…³ç³»")
        fail("Timeout waiting for commits - Complex LSU sequence test failed")
      }

      cd.waitSampling(10)
    }
  }

  test("SimpleLoad_Test") {
    // ä½¿ç”¨çº¯Scalaä»¿çœŸåç«¯é¿å¼€Verilatorè¯­æ³•é—®é¢˜
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex))

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(15000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(s"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0

      // é¢„å…ˆåˆå§‹åŒ–å†…å­˜åœ°å€0x100ä¸ºå·²çŸ¥å€¼
      val test_value = BigInt("deadbeef", 16)
      println(s"ğŸ”§ é¢„åˆå§‹åŒ–å†…å­˜ 0x100 = 0x${test_value.toString(16)}")
      dut.sram.io.tb_writeEnable #= true
      dut.sram.io.tb_writeAddress #= BigInt("100", 16) // ç›´æ¥ä½¿ç”¨å­—èŠ‚åœ°å€ï¼Œä¸DCacheä¸€è‡´
      dut.sram.io.tb_writeData #= test_value
      cd.waitSampling(2)
      dut.sram.io.tb_writeEnable #= false

      // éªŒè¯åˆå§‹åŒ–æˆåŠŸ
      val verify_value = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, BigInt("100", 16))
      println(s"ğŸ” éªŒè¯åˆå§‹åŒ–: å†…å­˜ 0x100 = 0x${verify_value.toString(16)}")
      assert(
        verify_value == test_value,
        s"Memory initialization failed: got 0x${verify_value.toString(16)}, expected 0x${test_value.toString(16)}"
      )

      // Simple commit monitoring with detailed logging
      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            commitCount += 1
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹LSU EUé›†æˆæµ‹è¯• ===")
      dut.io.enableCommit #= false
      cd.waitSampling(5)

      // ç®€åŒ–æµ‹è¯•ï¼šLoadæŒ‡ä»¤ï¼Œä½¿ç”¨å¯„å­˜å™¨0ï¼ˆæ€»æ˜¯0ï¼‰ä½œä¸ºåŸºå€ï¼Œä½†ä½¿ç”¨SRAMèŒƒå›´å†…çš„åœ°å€
      val instr_lw = LA32RInstrBuilder.ld_w(rd = 2, rj = 0, offset = 0x100) // r2 = MEM[r0 + 0x100] = MEM[0x100]
      println(s"[TEST] LoadæŒ‡ä»¤: ld.w r2, r0, 0x100 (insn=0x${instr_lw.toString(16)})")

      println("=== ğŸ“¤ å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start, instr_lw) // PC: 0x00000000

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆ ===")
      cd.waitSampling(20) // å¢åŠ ç­‰å¾…æ—¶é—´ç»™LSUæ›´å¤šå¤„ç†æ—¶é—´

      println("=== âœ… å¯ç”¨æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 200 // å¢åŠ è¶…æ—¶æ—¶é—´
      while (commitCount < 1 && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 50 == 0) {
          println(s"[WAIT] commitCount=$commitCount/1, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: LSUæµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº†${commitCount}æ¡æŒ‡ä»¤!")
        assert(commitCount == 1, s"Expected 1 commits, got $commitCount")
        // === éªŒè¯loadæŒ‡ä»¤ç»“æœ ===
        println("ğŸ” å¼€å§‹éªŒè¯loadæŒ‡ä»¤ç»“æœ...")
        cd.waitSampling(50) // ç­‰å¾…æ›´é•¿æ—¶é—´ç¡®ä¿æ•°æ®å†™å›

        // å…ˆæ£€æŸ¥ç‰©ç†å¯„å­˜å™¨æ˜ å°„
        val physReg2 = dut.ratMapping(2).toBigInt
        println(s"ğŸ“ å¯„å­˜å™¨r2æ˜ å°„åˆ°ç‰©ç†å¯„å­˜å™¨p${physReg2}")

        // éªŒè¯loadæŒ‡ä»¤æ˜¯å¦æ­£ç¡®è¯»å–äº†é¢„åˆå§‹åŒ–çš„å†…å­˜æ•°æ®å¹¶å­˜å‚¨åˆ°å¯„å­˜å™¨
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        println(s"ğŸ“ å¯„å­˜å™¨ r2 = 0x${r2_value.toString(16)} (æœŸæœ› 0x${test_value.toString(16)})")

        // å†æ¬¡æ£€æŸ¥å†…å­˜ä¸­çš„å€¼ç¡®è®¤åˆå§‹åŒ–æ­£ç¡®
        val current_mem_value = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, BigInt("100", 16))
        println(s"ğŸ“ å†…å­˜ 0x100 = 0x${current_mem_value.toString(16)} (ç¡®è®¤åˆå§‹åŒ–)")

        // éªŒè¯loadæŒ‡ä»¤æ­£ç¡®åœ°ä»å†…å­˜è¯»å–äº†é¢„åˆå§‹åŒ–çš„æ•°æ®
        assert(
          r2_value == test_value,
          s"Load instruction failed: r2=0x${r2_value.toString(16)}, expected 0x${test_value.toString(16)}. " +
            s"Memory contains 0x${current_mem_value.toString(16)}. " +
            s"Physical register mapping: r2->p${physReg2}"
        )

        println("âœ… LoadæŒ‡ä»¤éªŒè¯é€šè¿‡!")

      } else {
        println("âš ï¸ TIMEOUT: æŒ‡ä»¤æœªèƒ½åœ¨é¢„æœŸæ—¶é—´å†…æäº¤")
        println("è¿™å¯èƒ½è¡¨æ˜LSU EUçš„æŸä¸ªé˜¶æ®µå­˜åœ¨é—®é¢˜ï¼Œéœ€è¦åˆ†ææ—¥å¿—")
        fail("Timeout waiting for commits - LSU EU may have issues")
      }

      cd.waitSampling(5)
    }
  }

  test("MMIO_Path_Test_with_SRAM_check") {
    // Instantiate testbench with isIO = true, which forces all LSU operations
    // to bypass the D-Cache and use the MMIO path (SgmbService).
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = true))

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(30000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO è·¯å¾„ Store/Load æµ‹è¯• (éªŒè¯SRAM) ===")
      dut.io.enableCommit #= false
      cd.waitSampling(5)

      // Test sequence:
      // Since isIO=true, all accesses are MMIO. We can use low addresses.
      // 1. ADDI.W r3, r0, 0x0123              ; r3 = test_value
      // 2. ADDI.W r4, r0, 0x120               ; r4 = base_addr
      // 3. ST.W r3, r4, 0x200                 ; MEM[0x120 + 0x200] = r3
      // 4. LD.W r1, r4, 0x200                 ; r1 = MEM[0x320]

      val test_value = BigInt("0123", 16)
      val base_addr = BigInt("120", 16)
      val offset = 0x200
      val final_mmio_addr = base_addr + offset

      val instr1 = LA32RInstrBuilder.addi_w(rd = 3, rj = 0, imm = test_value.toInt)
      val instr2 = LA32RInstrBuilder.addi_w(rd = 4, rj = 0, imm = base_addr.toInt)
      val instr3 = LA32RInstrBuilder.st_w(rd = 3, rj = 4, offset = offset)
      val instr4 = LA32RInstrBuilder.ld_w(rd = 1, rj = 4, offset = offset)

      val totalInstructions = 4

      println(s"[TEST] ä¿®æ­£åçš„ MMIO è·¯å¾„æµ‹è¯•åºåˆ— (isIO=true):")
      println(f"  1. ADDI.W r3, r0, 0x${test_value.toInt}%x")
      println(f"  2. ADDI.W r4, r0, 0x${base_addr.toInt}%x")
      println(f"  3. ST.W r3, r4, 0x$offset%x -> Store to addr 0x${final_mmio_addr.toString(16)}")
      println(f"  4. LD.W r1, r4, 0x$offset%x -> Load from addr 0x${final_mmio_addr.toString(16)}")

      for (i <- 0 until totalInstructions) {
        expectedCommits += pc_start + i * 4
      }

      println("=== ğŸ“¤ å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start + 0, instr1)
      issueInstr(pc_start + 4, instr2)
      issueInstr(pc_start + 8, instr3)
      issueInstr(pc_start + 12, instr4)

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 600
      while (commitCount < totalInstructions && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: MMIO è·¯å¾„æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")
        assert(commitCount == totalInstructions, s"Expected ${totalInstructions} commits, got $commitCount")

        cd.waitSampling(20) // Give time for last operations to finalize

        println("=== ğŸ” éªŒè¯ MMIO æ“ä½œçš„æ­£ç¡®æ€§ ===")
        println(s"--- 1. ç›´æ¥æ£€æŸ¥SRAMå†…å­˜ ---")
        val mem_val = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, final_mmio_addr)
        assert(
          mem_val == test_value,
          s"SRAM content check failed! Address 0x${final_mmio_addr.toString(16)} contains 0x${mem_val
              .toString(16)}, expected 0x${test_value.toString(16)}"
        )
        println(f"âœ… MMIO Store æŒ‡ä»¤éªŒè¯é€šè¿‡: SRAM at 0x${final_mmio_addr.toString(16)} = 0x${mem_val.toString(16)}")

        println(s"--- 2. æ£€æŸ¥LoadæŒ‡ä»¤ç»“æœçš„ä½“ç³»ç»“æ„å¯„å­˜å™¨ ---")
        val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
        assert(
          r1_value == test_value,
          s"r1 final value check failed: Result was 0x${r1_value.toString(16)}, expected 0x${test_value.toString(16)}"
        )
        println(f"âœ… MMIO Load æŒ‡ä»¤éªŒè¯é€šè¿‡: r1 = 0x${r1_value}%x")

      } else {
        fail(
          s"Timeout waiting for commits - MMIO Path test failed. Committed ${commitCount}/${totalInstructions} instructions."
        )
      }
    }
  }

  test("MMIO_Load_Only_Test") {
    // This test focuses specifically on the MMIO read path,
    // bypassing store-to-load forwarding by pre-initializing memory.
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = true))

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(30000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO çº¯åŠ è½½æµ‹è¯• ===")

      // 1. Pre-initialize SRAM with a known value at the target MMIO address
      val test_value = BigInt("DAD", 16) // A value that fits in addi.w's immediate
      val base_addr = BigInt("600", 16)
      val offset = 0x88
      val final_mmio_addr = base_addr + offset

      println(s"ğŸ”§ é¢„åˆå§‹åŒ–SRAM: MEM[0x${final_mmio_addr.toString(16)}] = 0x${test_value.toString(16)}")
      dut.sram.io.tb_writeEnable #= true
      dut.sram.io.tb_writeAddress #= final_mmio_addr
      dut.sram.io.tb_writeData #= test_value
      cd.waitSampling(2)
      dut.sram.io.tb_writeEnable #= false
      cd.waitSampling(5)

      // Test sequence:
      // 1. ADDI.W r4, r0, 0x600               ; r4 = base_addr
      // 2. LD.W r1, r4, 0x88                  ; r1 = MEM[0x688]
      val instr1 = LA32RInstrBuilder.addi_w(rd = 4, rj = 0, imm = base_addr.toInt)
      val instr2 = LA32RInstrBuilder.ld_w(rd = 1, rj = 4, offset = offset)

      println(s"[TEST] MMIO çº¯åŠ è½½æµ‹è¯•åºåˆ— (isIO=true):")
      println(f"  1. ADDI.W r4, r0, 0x${base_addr.toInt}%x")
      println(f"  2. LD.W r1, r4, 0x$offset%x -> Load from addr 0x${final_mmio_addr.toString(16)}")

      expectedCommits += pc_start
      expectedCommits += pc_start + 4

      println("=== ğŸ“¤ å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start, instr1)
      issueInstr(pc_start + 4, instr2)

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 600
      while (commitCount < 2 && timeout > 0) { cd.waitSampling(); timeout -= 1 }

      assert(timeout > 0, "Timeout waiting for commits - MMIO Load Only Test failed.")
      println(s"ğŸ‰ SUCCESS: MMIO çº¯åŠ è½½æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")

      println("=== ğŸ” éªŒè¯ MMIO Load æ“ä½œçš„æ­£ç¡®æ€§ ===")
      cd.waitSampling(10) // Allow time for potential PRF writeback
      val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
      assert(
        r1_value == test_value,
        s"MMIO Load failed! r1 value was 0x${r1_value.toString(16)}, expected 0x${test_value.toString(16)}"
      )
      println(f"âœ… MMIO Load æŒ‡ä»¤éªŒè¯é€šè¿‡: r1 = 0x${r1_value.toString(16)}")
    }
  }
  testOnly("MMIO_Stress_Test_Multiple_Outstanding_Aligned") {
    // æµ‹è¯•å¤šä¸ªæœªå®Œæˆçš„MMIOæ“ä½œï¼ŒéªŒè¯LoadQueueèƒ½å¦æ­£ç¡®å¤„ç†å¹¶å‘MMIOè¯·æ±‚
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = true))
    
    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(40000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO å‹åŠ›æµ‹è¯•ï¼šå¤šä¸ªæœªå®Œæˆæ“ä½œ ===")

      // é¢„åˆå§‹åŒ–å¤šä¸ªå†…å­˜ä½ç½®
      val test_values = Array(0xAA0, 0xBB0, 0xCC0, 0xDDD, 0xEEE)
      val base_addrs = Array(0x100, 0x200, 0x300, 0x400, 0x500)
      
      for (i <- test_values.indices) {
        println(s"ğŸ”§ é¢„åˆå§‹åŒ–SRAM: MEM[0x${base_addrs(i).toHexString} = 0x${test_values(i).toHexString}")
        dut.sram.io.tb_writeEnable #= true
        dut.sram.io.tb_writeAddress #= base_addrs(i)
        dut.sram.io.tb_writeData #= test_values(i)
        cd.waitSampling(2)
        dut.sram.io.tb_writeEnable #= false
      }

      // å¤æ‚æµ‹è¯•åºåˆ—ï¼šå¿«é€Ÿè¿ç»­å‘å°„å¤šä¸ªMMIOè¯»æ“ä½œ
      // 1. ADDI r10, r0, 0x100  ; è®¾ç½®ç¬¬ä¸€ä¸ªåŸºå€
      // 2. ADDI r11, r0, 0x200  ; è®¾ç½®ç¬¬äºŒä¸ªåŸºå€  
      // 3. ADDI r12, r0, 0x300  ; è®¾ç½®ç¬¬ä¸‰ä¸ªåŸºå€
      // 4. LD.W r1, r10, 0x0   ; ä»0x100è¯»å– -> r1 = 0xAA0
      // 5. LD.W r2, r11, 0x0   ; ä»0x200è¯»å– -> r2 = 0xBB0 (å¯èƒ½ä¸ç¬¬4æ¡é‡å )
      // 6. LD.W r3, r12, 0x0   ; ä»0x300è¯»å– -> r3 = 0xCC0 (å¯èƒ½ä¸ç¬¬4ã€5æ¡é‡å )
      // 7. ST.W r1, r10, 0x10  ; å°†r1å­˜å‚¨åˆ°0x110 (ä¾èµ–äºLDå®Œæˆ)
      // 8. LD.W r4, r10, 0x10  ; ä»0x110è¯»å–éªŒè¯Store-to-Load forwarding

      val instr1 = LA32RInstrBuilder.addi_w(rd = 10, rj = 0, imm = base_addrs(0))
      val instr2 = LA32RInstrBuilder.addi_w(rd = 11, rj = 0, imm = base_addrs(1))
      val instr3 = LA32RInstrBuilder.addi_w(rd = 12, rj = 0, imm = base_addrs(2))
      val instr4 = LA32RInstrBuilder.ld_w(rd = 1, rj = 10, offset = 0)
      val instr5 = LA32RInstrBuilder.ld_w(rd = 2, rj = 11, offset = 0)
      val instr6 = LA32RInstrBuilder.ld_w(rd = 3, rj = 12, offset = 0)
      val instr7 = LA32RInstrBuilder.st_w(rd = 1, rj = 10, offset = 0x10)
      val instr8 = LA32RInstrBuilder.ld_w(rd = 4, rj = 10, offset = 0x10)

      val totalInstructions = 8

      println(s"[TEST] MMIO å‹åŠ›æµ‹è¯•åºåˆ— (isIO=true):")
      println(f"  1. ADDI.W r10, r0, 0x${base_addrs(0)}%x")
      println(f"  2. ADDI.W r11, r0, 0x${base_addrs(1)}%x")
      println(f"  3. ADDI.W r12, r0, 0x${base_addrs(2)}%x")
      println(f"  4. LD.W r1, r10, 0x0 -> Load from 0x${base_addrs(0)}%x")
      println(f"  5. LD.W r2, r11, 0x0 -> Load from 0x${base_addrs(1)}%x")
      println(f"  6. LD.W r3, r12, 0x0 -> Load from 0x${base_addrs(2)}%x")
      println(f"  7. ST.W r1, r10, 0x10 -> Store to 0x${base_addrs(0) + 0x10}%x")
      println(f"  8. LD.W r4, r10, 0x10 -> Load from 0x${base_addrs(0) + 0x10}%x (forwarding test)")

      for (i <- 0 until totalInstructions) {
        expectedCommits += pc_start + i * 4
      }

      println("=== ğŸ“¤ å¿«é€Ÿè¿ç»­å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start + 0, instr1)
      issueInstr(pc_start + 4, instr2)
      issueInstr(pc_start + 8, instr3)
      issueInstr(pc_start + 12, instr4)  // å¼€å§‹MMIOè¯»æ“ä½œ
      issueInstr(pc_start + 16, instr5)  // ç«‹å³å‘å°„ç¬¬äºŒä¸ªMMIOè¯»
      issueInstr(pc_start + 20, instr6)  // ç«‹å³å‘å°„ç¬¬ä¸‰ä¸ªMMIOè¯»
      issueInstr(pc_start + 24, instr7)  // Storeæ“ä½œï¼Œä¾èµ–äºinstr4çš„ç»“æœ
      issueInstr(pc_start + 28, instr8)  // Loadæ“ä½œï¼Œæµ‹è¯•forwarding

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 800
      while (commitCount < totalInstructions && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[PROGRESS] commitCount=$commitCount/$totalInstructions, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: MMIO å‹åŠ›æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")
        assert(commitCount == totalInstructions, s"Expected $totalInstructions commits, got $commitCount")

        cd.waitSampling(30) // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ

        println("=== ğŸ” éªŒè¯ MMIO å‹åŠ›æµ‹è¯•ç»“æœ ===")
        
        // éªŒè¯å¹¶å‘MMIOè¯»æ“ä½œçš„ç»“æœ
        val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)
        val r4_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 4)

        println(f"ğŸ“ å¹¶å‘MMIOè¯»ç»“æœ: r1=0x${r1_value}%x, r2=0x${r2_value}%x, r3=0x${r3_value}%x")
        println(f"ğŸ“ Store-to-Load forwardingç»“æœ: r4=0x${r4_value}%x")

        assert(r1_value == test_values(0), s"r1 MMIO read failed: got 0x${r1_value.toString(16)}, expected 0x${test_values(0).toHexString}")
        assert(r2_value == test_values(1), s"r2 MMIO read failed: got 0x${r2_value.toString(16)}, expected 0x${test_values(1).toHexString}")
        assert(r3_value == test_values(2), s"r3 MMIO read failed: got 0x${r3_value.toString(16)}, expected 0x${test_values(2).toHexString}")
        assert(r4_value == test_values(0), s"r4 forwarding failed: got 0x${r4_value.toString(16)}, expected 0x${test_values(0).toHexString}")

        // éªŒè¯MMIO Storeæ˜¯å¦æ­£ç¡®å†™å…¥å†…å­˜
        val stored_value = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, base_addrs(0) + 0x10)
        assert(stored_value == test_values(0), s"MMIO Store verification failed: memory contains 0x${stored_value.toString(16)}, expected 0x${test_values(0).toHexString}")

        println("âœ… MMIO å‹åŠ›æµ‹è¯•å®Œå…¨é€šè¿‡!")
        println("   éªŒè¯äº†: å¹¶å‘MMIOè¯»ã€MMIOå†™ã€Store-to-Load forwardingã€ä¾èµ–å¤„ç†")

      } else {
        fail(s"Timeout waiting for commits - MMIO Stress test failed. Committed $commitCount/$totalInstructions instructions.")
      }
    }
  }

  test("MMIO_Stress_Test_Multiple_Outstanding") {
    // æµ‹è¯•å¤šä¸ªæœªå®Œæˆçš„MMIOæ“ä½œï¼ŒéªŒè¯LoadQueueèƒ½å¦æ­£ç¡®å¤„ç†å¹¶å‘MMIOè¯·æ±‚
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = true))
    
    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(40000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO å‹åŠ›æµ‹è¯•ï¼šå¤šä¸ªæœªå®Œæˆæ“ä½œ ===")

      // é¢„åˆå§‹åŒ–å¤šä¸ªå†…å­˜ä½ç½®
      val test_values = Array(0xAAA, 0xBBB, 0xCCC, 0xDDD, 0xEEE)
      val base_addrs = Array(0x100, 0x200, 0x300, 0x400, 0x500)
      
      for (i <- test_values.indices) {
        println(s"ğŸ”§ é¢„åˆå§‹åŒ–SRAM: MEM[0x${base_addrs(i).toHexString} = 0x${test_values(i).toHexString}")
        dut.sram.io.tb_writeEnable #= true
        dut.sram.io.tb_writeAddress #= base_addrs(i)
        dut.sram.io.tb_writeData #= test_values(i)
        cd.waitSampling(2)
        dut.sram.io.tb_writeEnable #= false
      }

      // å¤æ‚æµ‹è¯•åºåˆ—ï¼šå¿«é€Ÿè¿ç»­å‘å°„å¤šä¸ªMMIOè¯»æ“ä½œ
      // 1. ADDI r10, r0, 0x100  ; è®¾ç½®ç¬¬ä¸€ä¸ªåŸºå€
      // 2. ADDI r11, r0, 0x200  ; è®¾ç½®ç¬¬äºŒä¸ªåŸºå€  
      // 3. ADDI r12, r0, 0x300  ; è®¾ç½®ç¬¬ä¸‰ä¸ªåŸºå€
      // 4. LD.W r1, r10, 0x0   ; ä»0x100è¯»å– -> r1 = 0xAAA
      // 5. LD.W r2, r11, 0x0   ; ä»0x200è¯»å– -> r2 = 0xBBB (å¯èƒ½ä¸ç¬¬4æ¡é‡å )
      // 6. LD.W r3, r12, 0x0   ; ä»0x300è¯»å– -> r3 = 0xCCC (å¯èƒ½ä¸ç¬¬4ã€5æ¡é‡å )
      // 7. ST.W r1, r10, 0x10  ; å°†r1å­˜å‚¨åˆ°0x110 (ä¾èµ–äºLDå®Œæˆ)
      // 8. LD.W r4, r10, 0x10  ; ä»0x110è¯»å–éªŒè¯Store-to-Load forwarding

      val instr1 = LA32RInstrBuilder.addi_w(rd = 10, rj = 0, imm = base_addrs(0))
      val instr2 = LA32RInstrBuilder.addi_w(rd = 11, rj = 0, imm = base_addrs(1))
      val instr3 = LA32RInstrBuilder.addi_w(rd = 12, rj = 0, imm = base_addrs(2))
      val instr4 = LA32RInstrBuilder.ld_w(rd = 1, rj = 10, offset = 0)
      val instr5 = LA32RInstrBuilder.ld_w(rd = 2, rj = 11, offset = 0)
      val instr6 = LA32RInstrBuilder.ld_w(rd = 3, rj = 12, offset = 0)
      val instr7 = LA32RInstrBuilder.st_w(rd = 1, rj = 10, offset = 0x10)
      val instr8 = LA32RInstrBuilder.ld_w(rd = 4, rj = 10, offset = 0x10)

      val totalInstructions = 8

      println(s"[TEST] MMIO å‹åŠ›æµ‹è¯•åºåˆ— (isIO=true):")
      println(f"  1. ADDI.W r10, r0, 0x${base_addrs(0)}%x")
      println(f"  2. ADDI.W r11, r0, 0x${base_addrs(1)}%x")
      println(f"  3. ADDI.W r12, r0, 0x${base_addrs(2)}%x")
      println(f"  4. LD.W r1, r10, 0x0 -> Load from 0x${base_addrs(0)}%x")
      println(f"  5. LD.W r2, r11, 0x0 -> Load from 0x${base_addrs(1)}%x")
      println(f"  6. LD.W r3, r12, 0x0 -> Load from 0x${base_addrs(2)}%x")
      println(f"  7. ST.W r1, r10, 0x10 -> Store to 0x${base_addrs(0) + 0x10}%x")
      println(f"  8. LD.W r4, r10, 0x10 -> Load from 0x${base_addrs(0) + 0x10}%x (forwarding test)")

      for (i <- 0 until totalInstructions) {
        expectedCommits += pc_start + i * 4
      }

      println("=== ğŸ“¤ å¿«é€Ÿè¿ç»­å‘å°„æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start + 0, instr1)
      issueInstr(pc_start + 4, instr2)
      issueInstr(pc_start + 8, instr3)
      issueInstr(pc_start + 12, instr4)  // å¼€å§‹MMIOè¯»æ“ä½œ
      issueInstr(pc_start + 16, instr5)  // ç«‹å³å‘å°„ç¬¬äºŒä¸ªMMIOè¯»
      issueInstr(pc_start + 20, instr6)  // ç«‹å³å‘å°„ç¬¬ä¸‰ä¸ªMMIOè¯»
      issueInstr(pc_start + 24, instr7)  // Storeæ“ä½œï¼Œä¾èµ–äºinstr4çš„ç»“æœ
      issueInstr(pc_start + 28, instr8)  // Loadæ“ä½œï¼Œæµ‹è¯•forwarding

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 800
      while (commitCount < totalInstructions && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[PROGRESS] commitCount=$commitCount/$totalInstructions, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: MMIO å‹åŠ›æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")
        assert(commitCount == totalInstructions, s"Expected $totalInstructions commits, got $commitCount")

        cd.waitSampling(30) // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ

        println("=== ğŸ” éªŒè¯ MMIO å‹åŠ›æµ‹è¯•ç»“æœ ===")
        
        // éªŒè¯å¹¶å‘MMIOè¯»æ“ä½œçš„ç»“æœ
        val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)
        val r4_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 4)

        println(f"ğŸ“ å¹¶å‘MMIOè¯»ç»“æœ: r1=0x${r1_value}%x, r2=0x${r2_value}%x, r3=0x${r3_value}%x")
        println(f"ğŸ“ Store-to-Load forwardingç»“æœ: r4=0x${r4_value}%x")

        assert(r1_value == test_values(0), s"r1 MMIO read failed: got 0x${r1_value.toString(16)}, expected 0x${test_values(0).toHexString}")
        assert(r2_value == test_values(1), s"r2 MMIO read failed: got 0x${r2_value.toString(16)}, expected 0x${test_values(1).toHexString}")
        assert(r3_value == test_values(2), s"r3 MMIO read failed: got 0x${r3_value.toString(16)}, expected 0x${test_values(2).toHexString}")
        assert(r4_value == test_values(0), s"r4 forwarding failed: got 0x${r4_value.toString(16)}, expected 0x${test_values(0).toHexString}")

        // éªŒè¯MMIO Storeæ˜¯å¦æ­£ç¡®å†™å…¥å†…å­˜
        val stored_value = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, base_addrs(0) + 0x10)
        assert(stored_value == test_values(0), s"MMIO Store verification failed: memory contains 0x${stored_value.toString(16)}, expected 0x${test_values(0).toHexString}")

        println("âœ… MMIO å‹åŠ›æµ‹è¯•å®Œå…¨é€šè¿‡!")
        println("   éªŒè¯äº†: å¹¶å‘MMIOè¯»ã€MMIOå†™ã€Store-to-Load forwardingã€ä¾èµ–å¤„ç†")

      } else {
        fail(s"Timeout waiting for commits - MMIO Stress test failed. Committed $commitCount/$totalInstructions instructions.")
      }
    }
  }

  test("MMIO_Mixed_Cache_Test") {
    // æµ‹è¯•MMIOå’Œç¼“å­˜æ“ä½œæ··åˆåœºæ™¯ï¼ŒéªŒè¯isIOæ ‡å¿—çš„æ­£ç¡®å¤„ç†
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = false)) // æ³¨æ„ï¼šisIO=falseï¼Œä½†æˆ‘ä»¬ä¼šæ‰‹åŠ¨æ§åˆ¶

    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(40000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}")
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO/Cache æ··åˆæµ‹è¯• ===")

      // é¢„åˆå§‹åŒ–å†…å­˜
      val cache_addr = 0x1000  // ç¼“å­˜åœ°å€èŒƒå›´
      val mmio_addr = 0x2000   // MMIOåœ°å€èŒƒå›´ (è¿™é‡Œå‡è®¾ï¼Œå®é™…ä¸­ç”±åœ°å€æ˜ å°„å†³å®š)
      val test_value1 = 0x1234
      val test_value2 = 0x5678

      println(s"ğŸ”§ é¢„åˆå§‹åŒ–å†…å­˜:")
      println(s"   CacheåŒºåŸŸ 0x${cache_addr.toHexString} = 0x${test_value1.toHexString}")
      println(s"   MMIOåŒºåŸŸ  0x${mmio_addr.toHexString} = 0x${test_value2.toHexString}")
      
      dut.sram.io.tb_writeEnable #= true
      dut.sram.io.tb_writeAddress #= cache_addr
      dut.sram.io.tb_writeData #= test_value1
      cd.waitSampling(2)
      dut.sram.io.tb_writeAddress #= mmio_addr
      dut.sram.io.tb_writeData #= test_value2
      cd.waitSampling(2)
      dut.sram.io.tb_writeEnable #= false

      // æ··åˆæµ‹è¯•åºåˆ—:
      // 1. ADDI r10, r0, 0x1000  ; CacheåŸºå€
      // 2. ADDI r11, r0, 0x2000  ; MMIOåŸºå€  
      // 3. LD.W r1, r10, 0x0     ; Cacheè¯»å– -> r1 = 0x1234
      // 4. LD.W r2, r11, 0x0     ; MMIOè¯»å– -> r2 = 0x5678 (æ³¨æ„ï¼šè¿™é‡Œå®é™…è¿˜æ˜¯èµ°Cacheï¼Œå› ä¸ºisIO=false)
      // 5. ST.W r1, r10, 0x10    ; Cacheå†™å…¥
      // 6. ST.W r2, r11, 0x10    ; MMIOå†™å…¥ (æ³¨æ„ï¼šå®é™…è¿˜æ˜¯èµ°Cache)
      // 7. LD.W r3, r10, 0x10    ; Cacheè¯»å–ï¼Œæµ‹è¯•Store-to-Load forwarding
      // 8. LD.W r4, r11, 0x10    ; MMIOè¯»å–ï¼Œæµ‹è¯•Store-to-Load forwarding

      val instr1 = LA32RInstrBuilder.addi_w(rd = 10, rj = 0, imm = cache_addr)
      val instr2 = LA32RInstrBuilder.addi_w(rd = 11, rj = 0, imm = mmio_addr)
      val instr3 = LA32RInstrBuilder.ld_w(rd = 1, rj = 10, offset = 0)
      val instr4 = LA32RInstrBuilder.ld_w(rd = 2, rj = 11, offset = 0)
      val instr5 = LA32RInstrBuilder.st_w(rd = 1, rj = 10, offset = 0x10)
      val instr6 = LA32RInstrBuilder.st_w(rd = 2, rj = 11, offset = 0x10)
      val instr7 = LA32RInstrBuilder.ld_w(rd = 3, rj = 10, offset = 0x10)
      val instr8 = LA32RInstrBuilder.ld_w(rd = 4, rj = 11, offset = 0x10)

      val totalInstructions = 8

      println(s"[TEST] Cache/MMIO æ··åˆæµ‹è¯•åºåˆ— (isIO=false):")
      println(f"  1. ADDI.W r10, r0, 0x${cache_addr}%x")
      println(f"  2. ADDI.W r11, r0, 0x${mmio_addr}%x")
      println(f"  3. LD.W r1, r10, 0x0 -> Cache Load from 0x${cache_addr}%x")
      println(f"  4. LD.W r2, r11, 0x0 -> Cache Load from 0x${mmio_addr}%x")
      println(f"  5. ST.W r1, r10, 0x10 -> Cache Store to 0x${cache_addr + 0x10}%x")
      println(f"  6. ST.W r2, r11, 0x10 -> Cache Store to 0x${mmio_addr + 0x10}%x")
      println(f"  7. LD.W r3, r10, 0x10 -> Cache Load from 0x${cache_addr + 0x10}%x (forwarding)")
      println(f"  8. LD.W r4, r11, 0x10 -> Cache Load from 0x${mmio_addr + 0x10}%x (forwarding)")

      for (i <- 0 until totalInstructions) {
        expectedCommits += pc_start + i * 4
      }

      println("=== ğŸ“¤ å‘å°„æ··åˆæŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start + 0, instr1)
      issueInstr(pc_start + 4, instr2)
      issueInstr(pc_start + 8, instr3)
      issueInstr(pc_start + 12, instr4)
      issueInstr(pc_start + 16, instr5)
      issueInstr(pc_start + 20, instr6)
      issueInstr(pc_start + 24, instr7)
      issueInstr(pc_start + 28, instr8)

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 800
      while (commitCount < totalInstructions && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[PROGRESS] commitCount=$commitCount/$totalInstructions, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: Cache/MMIO æ··åˆæµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")
        assert(commitCount == totalInstructions, s"Expected $totalInstructions commits, got $commitCount")

        cd.waitSampling(30)

        println("=== ğŸ” éªŒè¯ Cache/MMIO æ··åˆæµ‹è¯•ç»“æœ ===")
        
        val r1_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 1)
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)
        val r4_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 4)

        println(f"ğŸ“ Cacheè¯»å–ç»“æœ: r1=0x${r1_value}%x, r2=0x${r2_value}%x")
        println(f"ğŸ“ Forwardingç»“æœ: r3=0x${r3_value}%x, r4=0x${r4_value}%x")

        assert(r1_value == test_value1, s"Cache read failed: r1=0x${r1_value.toString(16)}, expected 0x${test_value1.toHexString}")
        assert(r2_value == test_value2, s"Cache read failed: r2=0x${r2_value.toString(16)}, expected 0x${test_value2.toHexString}")
        assert(r3_value == test_value1, s"Cache forwarding failed: r3=0x${r3_value.toString(16)}, expected 0x${test_value1.toHexString}")
        assert(r4_value == test_value2, s"Cache forwarding failed: r4=0x${r4_value.toString(16)}, expected 0x${test_value2.toHexString}")

        // éªŒè¯æ•°æ®ç¡®å®è¢«å†™å…¥å†…å­˜
        val stored_value1 = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, cache_addr + 0x10)
        val stored_value2 = IssueToAluAndLsuSpecHelper.readMemoryWord(dut, mmio_addr + 0x10)
        
        assert(stored_value1 == test_value1, s"Cache store verification failed: memory contains 0x${stored_value1.toString(16)}, expected 0x${test_value1.toHexString}")
        assert(stored_value2 == test_value2, s"Cache store verification failed: memory contains 0x${stored_value2.toString(16)}, expected 0x${test_value2.toHexString}")

        println("âœ… Cache/MMIO æ··åˆæµ‹è¯•å®Œå…¨é€šè¿‡!")
        println("   éªŒè¯äº†: Cacheè¯»å†™ã€Store-to-Load forwardingã€å†…å­˜ä¸€è‡´æ€§")

      } else {
        fail(s"Timeout waiting for commits - Mixed Cache/MMIO test failed. Committed $commitCount/$totalInstructions instructions.")
      }
    }
  }

  test("MMIO_Error_Handling_Test") {
    // æµ‹è¯•MMIOé”™è¯¯å¤„ç†è·¯å¾„ï¼ŒéªŒè¯å¼‚å¸¸å¤„ç†æœºåˆ¶
    val compiled = SimConfig
      .withConfig(
        SpinalConfig().copy(
          defaultConfigForClockDomains = ClockDomainConfig(resetKind = SYNC),
          targetDirectory = "simWorkspace/scala_sim"
        )
      )
      .compile(new IssueToAluAndLsuTestBench(pCfg_complex, isIO = true))
    
    compiled.doSim { dut =>
      val cd = dut.clockDomain
      cd.forkStimulus(period = 10)
      SimTimeout(30000)

      def issueInstr(pc: BigInt, insn: BigInt): Unit = {
        println(f"[ISSUE] PC=0x${pc.toString(16)}, insn=0x${insn.toString(16)}")
        dut.io.fetchStreamIn.valid #= true
        dut.io.fetchStreamIn.payload.pc #= pc
        dut.io.fetchStreamIn.payload.instruction #= insn
        dut.io.fetchStreamIn.payload.predecode.setDefaultForSim()
        dut.io.fetchStreamIn.payload.bpuPrediction.wasPredicted #= false
        cd.waitSamplingWhere(dut.io.fetchStreamIn.ready.toBoolean)
        dut.io.fetchStreamIn.valid #= false
        cd.waitSampling(1)
      }

      val pc_start = BigInt("00000000", 16)
      var commitCount = 0
      val expectedCommits = scala.collection.mutable.Queue[BigInt]()

      val commitMonitor = fork {
        while (true) {
          cd.waitSampling()
          if (dut.io.enableCommit.toBoolean && dut.io.commitValid.toBoolean) {
            val commitPC = dut.io.commitEntry.payload.uop.decoded.pc.toBigInt
            val hasException = dut.io.commitEntry.status.hasException.toBoolean
            val exceptionCode = if (hasException) dut.io.commitEntry.status.exceptionCode.toBigInt else BigInt(0)
            
            println(s"[COMMIT] âœ… PC=0x${commitPC.toString(16)}, exception=$hasException, code=0x${exceptionCode.toString(16)}")
            
            if (expectedCommits.nonEmpty) {
              val expectedPC = expectedCommits.dequeue()
              assert(
                commitPC == expectedPC,
                s"PC mismatch: expected 0x${expectedPC.toString(16)}, got 0x${commitPC.toString(16)}"
              )
              commitCount += 1
            }
          }
        }
      }

      println("=== ğŸš€ å¼€å§‹ MMIO é”™è¯¯å¤„ç†æµ‹è¯• ===")

      // æµ‹è¯•åºåˆ—ï¼š
      // 1. ADDI r10, r0, 0x7FFE  ; å‡†å¤‡ä¸€ä¸ªå¯èƒ½å¯¼è‡´å¯¹é½é”™è¯¯çš„åœ°å€ 
      // 2. LD.W r1, r10, 0x1    ; éå¯¹é½è®¿é—® (0x7FFF)ï¼Œåº”è¯¥äº§ç”Ÿå¯¹é½å¼‚å¸¸
      // 3. ADDI r11, r0, 0x1000 ; æ­£å¸¸åœ°å€
      // 4. LD.W r2, r11, 0x0    ; æ­£å¸¸MMIOè¯»å–
      // 5. ADDI r12, r0, 0x8000 ; è¶…å‡ºèŒƒå›´çš„åœ°å€(å¦‚æœæœ‰çš„è¯)
      // 6. LD.W r3, r12, 0x0    ; å¯èƒ½çš„è®¿é—®é”™è¯¯

      val instr1 = LA32RInstrBuilder.addi_w(rd = 10, rj = 0, imm = 0x7FFE)
      val instr2 = LA32RInstrBuilder.ld_w(rd = 1, rj = 10, offset = 0x1)  // 0x7FFF - é4å­—èŠ‚å¯¹é½
      val instr3 = LA32RInstrBuilder.addi_w(rd = 11, rj = 0, imm = 0x1000)
      val instr4 = LA32RInstrBuilder.ld_w(rd = 2, rj = 11, offset = 0x0)
      val instr5 = LA32RInstrBuilder.addi_w(rd = 12, rj = 0, imm = 0x3000)
      val instr6 = LA32RInstrBuilder.ld_w(rd = 3, rj = 12, offset = 0x0)

      // é¢„åˆå§‹åŒ–æ­£å¸¸åœ°å€çš„å†…å­˜
      val test_value = 0x9999
      println(s"ğŸ”§ é¢„åˆå§‹åŒ–SRAM: MEM[0x1000] = 0x${test_value.toHexString}")
      dut.sram.io.tb_writeEnable #= true
      dut.sram.io.tb_writeAddress #= 0x1000
      dut.sram.io.tb_writeData #= test_value
      cd.waitSampling(2)
      dut.sram.io.tb_writeEnable #= false
      
      println(s"ğŸ”§ é¢„åˆå§‹åŒ–SRAM: MEM[0x3000] = 0x${test_value.toHexString}")
      dut.sram.io.tb_writeAddress #= 0x3000
      dut.sram.io.tb_writeData #= test_value
      cd.waitSampling(2)

      val totalInstructions = 6

      println(s"[TEST] MMIO é”™è¯¯å¤„ç†æµ‹è¯•åºåˆ— (isIO=true):")
      println(f"  1. ADDI.W r10, r0, 0x7FFE")
      println(f"  2. LD.W r1, r10, 0x1 -> éå¯¹é½è®¿é—® 0x7FFF (å¯èƒ½å¼‚å¸¸)")
      println(f"  3. ADDI.W r11, r0, 0x1000")
      println(f"  4. LD.W r2, r11, 0x0 -> æ­£å¸¸MMIOè®¿é—® 0x1000")
      println(f"  5. ADDI.W r12, r0, 0x3000")
      println(f"  6. LD.W r3, r12, 0x0 -> æ­£å¸¸MMIOè®¿é—® 0x3000")

      for (i <- 0 until totalInstructions) {
        expectedCommits += pc_start + i * 4
      }

      println("=== ğŸ“¤ å‘å°„é”™è¯¯å¤„ç†æµ‹è¯•æŒ‡ä»¤åºåˆ— ===")
      issueInstr(pc_start + 0, instr1)
      issueInstr(pc_start + 4, instr2)
      issueInstr(pc_start + 8, instr3)
      issueInstr(pc_start + 12, instr4)
      issueInstr(pc_start + 16, instr5)
      issueInstr(pc_start + 20, instr6)

      println("=== â±ï¸ ç­‰å¾…æ‰§è¡Œå®Œæˆå¹¶æäº¤ ===")
      dut.io.enableCommit #= true

      var timeout = 600
      while (commitCount < totalInstructions && timeout > 0) {
        cd.waitSampling()
        timeout -= 1
        if (timeout % 100 == 0) {
          println(s"[PROGRESS] commitCount=$commitCount/$totalInstructions, timeout=$timeout")
        }
      }

      if (timeout > 0) {
        println(s"ğŸ‰ SUCCESS: MMIO é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸæäº¤äº† ${commitCount} æ¡æŒ‡ä»¤!")
        assert(commitCount == totalInstructions, s"Expected $totalInstructions commits, got $commitCount")

        cd.waitSampling(20)

        println("=== ğŸ” éªŒè¯ MMIO é”™è¯¯å¤„ç†ç»“æœ ===")
        
        // éªŒè¯æ­£å¸¸æ“ä½œçš„ç»“æœ
        val r2_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 2)
        val r3_value = IssueToAluAndLsuSpecHelper.readArchReg(dut, 3)

        println(f"ğŸ“ æ­£å¸¸MMIOæ“ä½œç»“æœ: r2=0x${r2_value}%x, r3=0x${r3_value}%x")

        assert(r2_value == test_value, s"Normal MMIO read failed: r2=0x${r2_value.toString(16)}, expected 0x${test_value.toHexString}")
        assert(r3_value == test_value, s"Normal MMIO read failed: r3=0x${r3_value.toString(16)}, expected 0x${test_value.toHexString}")

        println("âœ… MMIO é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡!")
        println("   éªŒè¯äº†: å¼‚å¸¸å¤„ç†ã€æ­£å¸¸æ“ä½œã€é”™è¯¯æ¢å¤")

      } else {
        fail(s"Timeout waiting for commits - MMIO Error Handling test failed. Committed $commitCount/$totalInstructions instructions.")
      }
    }
  }

  thatsAll()
}
